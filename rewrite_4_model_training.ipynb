{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from mobilenet_sipeed.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev_image_generator(input_feed,data_folder, bs, mode=\"train\", aug=None):\n",
    "    index = 0\n",
    "    \n",
    "    NUM_IMAGES = len(input_feed)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # initialize our batches of images and labels\n",
    "        images = []\n",
    "        poly_cof = []\n",
    "        \n",
    "        # keep looping until we reach our batch size\n",
    "        while len(images) < bs:\n",
    "            \n",
    "            line = input_feed[index]\n",
    "            index = index + 1\n",
    "            if index >= len(input_feed):\n",
    "                index = 0;\n",
    "            \n",
    "            center_img_path = line[0]\n",
    "            file_name = center_img_path\n",
    "#             print('./{}/{}'.format(folder, file_name))\n",
    "            \n",
    "            if len(file_name) > 0:\n",
    "                image = cv2.imread(file_name)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                image = cv2.resize(image,(96,96))\n",
    "                \n",
    "                if image is not None:\n",
    "                    pixels = np.array(image,dtype='f')\n",
    "#                     pixels = pixels.astype('float32')\n",
    "                    pixels = pixels/255\n",
    "                    images.append(pixels)\n",
    "    #                 images.append(np.fliplr(image))\n",
    "\n",
    "                    x0 = (float(line[1])+float(line[3]))/2\n",
    "                    y0 = (float(line[2])+float(line[4]))/2\n",
    "                    x1 = (float(line[5])+float(line[7]))/2\n",
    "                    y1 = (float(line[6])+float(line[8]))/2\n",
    "                    x2 = float(line[9])\n",
    "                    y2 = float(line[10])\n",
    "                    \n",
    "                    x0x1 = math.sqrt(math.pow(x0-x1, 2)+math.pow(y0-y1, 2))\n",
    "                    x0x2 = math.sqrt(math.pow(x2-x0, 2)+math.pow(y2-y0, 2))\n",
    "                    x1x2 = math.sqrt(math.pow(x2-x1, 2)+math.pow(y2-y1, 2))\n",
    "#                     tongg = line[1:]\n",
    "\n",
    "#                     tongg2 = np.array(tongg,dtype='f')\n",
    "# #                     tongg = tongg.astype(np.float)\n",
    "#                     tongg2 = tongg2/128\n",
    "# #                     tongg2 = tongg2*0.75\n",
    "#                     tongg2 = tongg2.tolist()\n",
    "                    poly_cof.append([x0x1/128,x0x2/128,x1x2/128])\n",
    "               \n",
    "        \n",
    "        # if the data augmentation object is not None, apply it\n",
    "        if aug is not None:\n",
    "            (images, labels) = next(aug.flow(np.array(images),\n",
    "                labels, batch_size=bs))\n",
    "        # yield the batch to the calling function\n",
    "#         print(poly_cof)\n",
    "        yield (np.array(images), np.array(poly_cof))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading all data and sepperate to train dataset and valdidate dataset ##\n",
    "\n",
    "image_load_data = []\n",
    "image_load_data_v = []\n",
    "\n",
    "with open('data_out.csv') as f:\n",
    "\n",
    "    reader = csv.reader(f)\n",
    "    for csv_line in reader:\n",
    "        if len(csv_line)>1 :\n",
    "            image_load_data.append(csv_line)\n",
    "\n",
    "with open('data_out_v.csv') as f:\n",
    "\n",
    "    reader = csv.reader(f)\n",
    "    for csv_line in reader:\n",
    "        if len(csv_line)>1 :\n",
    "            image_load_data_v.append(csv_line)\n",
    "        \n",
    "image_load_data = shuffle(image_load_data)\n",
    "image_load_data_v = shuffle(image_load_data_v)\n",
    "# data_train, data_test  = train_test_split(image_load_data,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.603515625, 0.369140625, 0.509765625, 0.36328125, 0.28125, 0.3515625, 0.369140625, 0.357421875, 0.41015625, 0.52734375]]\n"
     ]
    }
   ],
   "source": [
    "poly_cof=[]\n",
    "image_load_data_v[0]\n",
    "tongg = image_load_data_v[3][1:]\n",
    "\n",
    "tongg = np.array(tongg,dtype='f')\n",
    "# tongg = tongg.astype(np.float)\n",
    "tongg = tongg/128\n",
    "tongg = tongg*0.75\n",
    "tongg = tongg.tolist()\n",
    "poly_cof.append(tongg)\n",
    "print(poly_cof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []\n",
    "image = cv2.imread(image_load_data_v[0][0])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = cv2.resize(image,(96,96))\n",
    "pixels = np.array(image,dtype='f')\n",
    "pixels = pixels/255\n",
    "images.append(pixels)\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_cof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for and batch_size\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# initialize the total number of training and testing image\n",
    "NUM_TRAIN_IMAGES = len(image_load_data)\n",
    "NUM_TEST_IMAGES = len(image_load_data_v)\n",
    "ft = 'img'\n",
    "fv='img_v'\n",
    "trainGen = dev_image_generator(image_load_data,ft, BATCH_SIZE, mode = \"train\", aug = None)\n",
    "testGen = dev_image_generator(image_load_data_v,fv, BATCH_SIZE, mode = \"train\", aug = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 98, 98, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 48, 48, 8)         216       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 48, 48, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 48, 48, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 48, 48, 8)         72        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 48, 48, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 48, 48, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 48, 48, 16)        128       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 24, 24, 16)        144       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 24, 24, 32)        512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 24, 24, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 24, 24, 32)        1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 12, 12, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 12, 12, 64)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 64)          576       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 6, 6, 128)         8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 6, 6, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 6, 6, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 6, 6, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 6, 6, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 6, 6, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 6, 6, 128)         16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 3, 3, 128)         1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 3, 3, 256)         32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 3, 3, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 3, 3, 256)         65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                3855      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 222,447\n",
      "Trainable params: 216,975\n",
      "Non-trainable params: 5,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize our Keras model and compile it\n",
    "\n",
    "base_model=MobileNet(input_shape=(96, 96, 3), alpha = 0.25,depth_multiplier = 1, dropout = 0.001,include_top = False, weights = None, classes = 1000, backend=keras.backend, layers=keras.layers,models=keras.models,utils=keras.utils)\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(15,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "# x=Dropout(0.1)(x)\n",
    "# x=Dense(50,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(3)(x) #final layer with softmax activation\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "# from keras.layers import Flatten, Dense\n",
    "\n",
    "\n",
    "# ## TODO: Specify a CNN architecture\n",
    "# # Your model should accept 96x96 pixel graysale images in\n",
    "# # It should have a fully-connected output layer with 30 values (2 for each facial keypoint)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, (5, 5), input_shape=(96,96,3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# # model.add(Dense(256, activation='relu'))\n",
    "# # model.add(Dense(128, activation='relu'))\n",
    "# # model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(3))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "# model.summary()\n",
    "\n",
    "filepath=\"w-imp-{epoch:02d}-{val_loss:.5f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training w/ generator...\n",
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "3709/3709 [==============================] - 213s 57ms/step - loss: 0.0071 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00429, saving model to w-imp-01-0.00429.h5\n",
      "Epoch 2/10\n",
      "3709/3709 [==============================] - 225s 61ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00429\n",
      "Epoch 3/10\n",
      "3709/3709 [==============================] - 223s 60ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00429\n",
      "Epoch 4/10\n",
      "3709/3709 [==============================] - 222s 60ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00429 to 0.00341, saving model to w-imp-04-0.00341.h5\n",
      "Epoch 5/10\n",
      "3709/3709 [==============================] - 225s 61ms/step - loss: 0.0042 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00341\n",
      "Epoch 6/10\n",
      " 161/3709 [>.............................] - ETA: 2:56 - loss: 0.0043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-b59bca69f97c>\", line 6, in <module>\n",
      "    epochs=NUM_EPOCHS, callbacks=callbacks_list)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training.py\", line 1732, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 220, in fit_generator\n",
      "    reset_metrics=False)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\contrib\\__init__.py\", line 48, in <module>\n",
      "    from tensorflow.contrib import estimator\n",
      "  File \"C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\contrib\\estimator\\__init__.py\", line 30, in <module>\n",
      "    from tensorflow_estimator.contrib import estimator\n",
      "ModuleNotFoundError: No module named 'tensorflow_estimator.contrib'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "\n",
    "print(\"[INFO] training w/ generator...\")\n",
    "H = model.fit_generator(trainGen, steps_per_epoch=NUM_TRAIN_IMAGES // BATCH_SIZE, \n",
    "                        validation_data=testGen, validation_steps=NUM_TEST_IMAGES // BATCH_SIZE, \n",
    "                        epochs=NUM_EPOCHS, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('road_following_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ER9X\\Anaconda3\\envs\\yolo\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"w-imp-09-0.00697.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb948732f2fe48d6917c74f703b5a5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5425045dc444ba2948de5b5b4ac0c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='value')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets\n",
    "def bgr8_to_jpeg(value, quality=75):\n",
    "    return bytes(cv2.imencode('.jpg', value)[1])\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    \n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "image_widget2 = ipywidgets.Label('data')\n",
    "image_widget2.value = 'value'\n",
    "\n",
    "display(image_widget,image_widget2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3262484373034487\n"
     ]
    }
   ],
   "source": [
    "crop_img = cv2.imread('3.jpg')\n",
    "# crop_img = cv2.resize(crop_img,(128,128))\n",
    "\n",
    "# \n",
    "# img2 = cv2.rectangle(img, (130,180),(130+90,240), (0,0,0), -1) \n",
    "img2 = cv2.resize(crop_img,(96,96))\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_5_face_landmarks.dat\")\n",
    "tong = dlib.rectangle(0,0,128,128)\n",
    "img_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "landmarks = predictor(img_gray,tong)\n",
    "\n",
    "\n",
    "landmarks_list=[]\n",
    "for i in range(0, landmarks.num_parts):\n",
    "#     tong5 = str(landmarks.part(i).x), str(landmarks.part(i).y)\n",
    "    landmarks_list.append((landmarks.part(i).x))\n",
    "    landmarks_list.append((landmarks.part(i).y))\n",
    "    \n",
    "# img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "pixels = np.array(img2)\n",
    "pixels = pixels.astype('float32')\n",
    "pixels = pixels/255\n",
    "\n",
    "img3 = pixels[None, :, :, :]\n",
    "steering_angle = model.predict(img3)[0]\n",
    "ttt = steering_angle*96\n",
    "# for n in range(0, 5):\n",
    "#     tttt = n*2\n",
    "#     x = ttt[tttt]\n",
    "#     y = ttt[tttt+1]\n",
    "#     cv2.circle(img2, (x, y), 3, (255, 0, 0), -1)\n",
    "\n",
    "\n",
    "x0 = (landmarks_list[0]+landmarks_list[2])/2\n",
    "y0 = (landmarks_list[1]+landmarks_list[3])/2\n",
    "x1 = (landmarks_list[4]+landmarks_list[6])/2\n",
    "y1 = (landmarks_list[5]+landmarks_list[7])/2\n",
    "x2 = float(landmarks_list[8])\n",
    "y2 = float(landmarks_list[9])\n",
    "\n",
    "cv2.circle(img2, (int(x0), int(y0)), 4, (255, 0, 0), -1)\n",
    "cv2.circle(img2, (int(x1), int(y1)), 4, (255, 0, 0), -1)\n",
    "cv2.circle(img2, (int(x2), int(y2)), 4, (255, 0, 0), -1)\n",
    "image_widget.value = bgr8_to_jpeg(img2)\n",
    "\n",
    "x0x1 = math.sqrt(math.pow(x0-x1, 2)+math.pow(y0-y1, 2))\n",
    "x0x2 = math.sqrt(math.pow(x2-x0, 2)+math.pow(y2-y0, 2))\n",
    "x1x2 = math.sqrt(math.pow(x2-x1, 2)+math.pow(y2-y1, 2))\n",
    "\n",
    "# print()\n",
    "# print(ttt)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "teee = np.array([x0x1,x0x2,x1x2])\n",
    "teee2 = np.array(ttt)\n",
    "print(rmse(np.array(teee2), np.array(teee)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "poly_cof = []\n",
    "poly_cof.append([x0x1/128,x0x2/128,x1x2/128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.37743351028691136, 0.3114974151553067, 0.48937377773634083]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_cof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "teee = np.array([59,23,63])\n",
    "teee2 = np.array([x0x1,x0x2,x1x2])\n",
    "print(rmse(np.array(teee2), np.array(teee)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([59, 23, 63]), array([48.31148932, 39.87166914, 62.63984355]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teee,teee2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.532955574646952\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
